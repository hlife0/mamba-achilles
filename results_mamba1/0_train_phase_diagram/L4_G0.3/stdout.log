Configuration saved to results/0_train_phase_diagram/L4_G0.3/config.json
Using device: cuda
Creating datasets...
Train dataset size: 300000
Eval dataset size: 1800
Creating model: MambaForComposite
Model parameters: 129,184

Starting training for 200 epochs...
Epoch 1/200 | Loss: 5.5758 | LR: 0.000010
Epoch 2/200 | Loss: 5.5584 | LR: 0.000034
Epoch 3/200 | Loss: 5.5269 | LR: 0.000058
Epoch 4/200 | Loss: 5.4831 | LR: 0.000082
Epoch 5/200 | Loss: 5.4328 | LR: 0.000106
Epoch 6/200 | Loss: 5.3751 | LR: 0.000130
Epoch 7/200 | Loss: 5.3084 | LR: 0.000154
Epoch 8/200 | Loss: 5.2367 | LR: 0.000178
Epoch 9/200 | Loss: 5.1533 | LR: 0.000202
Epoch 10/200 | Loss: 5.0472 | Comp Acc: 0.0133 (best: 0.0133@10) | Sym Acc: 0.0094 (best: 0.0094@10) | LR: 0.000226
Epoch 11/200 | Loss: 4.9139 | LR: 0.000250
Epoch 12/200 | Loss: 4.7594 | LR: 0.000250
Epoch 13/200 | Loss: 4.6462 | LR: 0.000250
Epoch 14/200 | Loss: 4.5737 | LR: 0.000250
Epoch 15/200 | Loss: 4.5382 | LR: 0.000250
Epoch 16/200 | Loss: 4.5226 | LR: 0.000250
Epoch 17/200 | Loss: 4.5160 | LR: 0.000249
Epoch 18/200 | Loss: 4.5132 | LR: 0.000249
Epoch 19/200 | Loss: 4.5117 | LR: 0.000249
Epoch 20/200 | Loss: 4.5110 | Comp Acc: 0.0067 (best: 0.0133@10) | Sym Acc: 0.0172 (best: 0.0172@20) | LR: 0.000249
Epoch 21/200 | Loss: 4.5103 | LR: 0.000248
Epoch 22/200 | Loss: 4.5099 | LR: 0.000248
Epoch 23/200 | Loss: 4.5094 | LR: 0.000248
Epoch 24/200 | Loss: 4.5088 | LR: 0.000247
Epoch 25/200 | Loss: 4.5084 | LR: 0.000247
Epoch 26/200 | Loss: 4.5075 | LR: 0.000246
Epoch 27/200 | Loss: 4.5069 | LR: 0.000246
Epoch 28/200 | Loss: 4.5059 | LR: 0.000245
Epoch 29/200 | Loss: 4.5046 | LR: 0.000245
Epoch 30/200 | Loss: 4.5035 | Comp Acc: 0.0183 (best: 0.0183@30) | Sym Acc: 0.0128 (best: 0.0172@20) | LR: 0.000244
Epoch 31/200 | Loss: 4.5018 | LR: 0.000243
Epoch 32/200 | Loss: 4.4995 | LR: 0.000243
Epoch 33/200 | Loss: 4.4966 | LR: 0.000242
Epoch 34/200 | Loss: 4.4931 | LR: 0.000241
Epoch 35/200 | Loss: 4.4874 | LR: 0.000241
Epoch 36/200 | Loss: 4.4796 | LR: 0.000240
Epoch 37/200 | Loss: 4.4663 | LR: 0.000239
Epoch 38/200 | Loss: 4.4452 | LR: 0.000238
Epoch 39/200 | Loss: 4.4088 | LR: 0.000237
Epoch 40/200 | Loss: 4.3317 | Comp Acc: 0.0261 (best: 0.0261@40) | Sym Acc: 0.0111 (best: 0.0172@20) | LR: 0.000236
Epoch 41/200 | Loss: 4.1826 | LR: 0.000236
Epoch 42/200 | Loss: 4.0165 | LR: 0.000235
Epoch 43/200 | Loss: 3.8526 | LR: 0.000234
Epoch 44/200 | Loss: 3.6834 | LR: 0.000233
Epoch 45/200 | Loss: 3.5082 | LR: 0.000232
Epoch 46/200 | Loss: 3.3194 | LR: 0.000230
Epoch 47/200 | Loss: 3.0927 | LR: 0.000229
Epoch 48/200 | Loss: 2.8534 | LR: 0.000228
Epoch 49/200 | Loss: 2.6177 | LR: 0.000227
Epoch 50/200 | Loss: 2.3953 | Comp Acc: 0.1367 (best: 0.1367@50) | Sym Acc: 0.0344 (best: 0.0344@50) | LR: 0.000226
Epoch 51/200 | Loss: 2.1904 | LR: 0.000225
Epoch 52/200 | Loss: 1.9978 | LR: 0.000223
Epoch 53/200 | Loss: 1.8184 | LR: 0.000222
Epoch 54/200 | Loss: 1.6471 | LR: 0.000221
Epoch 55/200 | Loss: 1.4909 | LR: 0.000220
Epoch 56/200 | Loss: 1.3508 | LR: 0.000218
Epoch 57/200 | Loss: 1.2094 | LR: 0.000217
Epoch 58/200 | Loss: 1.0904 | LR: 0.000216
Epoch 59/200 | Loss: 0.9764 | LR: 0.000214
Epoch 60/200 | Loss: 0.8618 | Comp Acc: 0.1461 (best: 0.1461@60) | Sym Acc: 0.0172 (best: 0.0344@50) | LR: 0.000213
Epoch 61/200 | Loss: 0.7604 | LR: 0.000211
Epoch 62/200 | Loss: 0.6729 | LR: 0.000210
Epoch 63/200 | Loss: 0.5974 | LR: 0.000208
Epoch 64/200 | Loss: 0.5307 | LR: 0.000207
Epoch 65/200 | Loss: 0.4667 | LR: 0.000205
Epoch 66/200 | Loss: 0.4168 | LR: 0.000204
Epoch 67/200 | Loss: 0.3702 | LR: 0.000202
Epoch 68/200 | Loss: 0.3258 | LR: 0.000201
Epoch 69/200 | Loss: 0.2874 | LR: 0.000199
Epoch 70/200 | Loss: 0.2528 | Comp Acc: 0.0478 (best: 0.1461@60) | Sym Acc: 0.0044 (best: 0.0344@50) | LR: 0.000197
Epoch 71/200 | Loss: 0.2222 | LR: 0.000196
Epoch 72/200 | Loss: 0.1950 | LR: 0.000194
Epoch 73/200 | Loss: 0.1705 | LR: 0.000192
Epoch 74/200 | Loss: 0.1506 | LR: 0.000191
Epoch 75/200 | Loss: 0.1340 | LR: 0.000189
Epoch 76/200 | Loss: 0.1193 | LR: 0.000187
Epoch 77/200 | Loss: 0.1056 | LR: 0.000185
Epoch 78/200 | Loss: 0.0941 | LR: 0.000184
Epoch 79/200 | Loss: 0.0839 | LR: 0.000182
Epoch 80/200 | Loss: 0.0756 | Comp Acc: 0.0139 (best: 0.1461@60) | Sym Acc: 0.0039 (best: 0.0344@50) | LR: 0.000180
Epoch 81/200 | Loss: 0.0677 | LR: 0.000178
Epoch 82/200 | Loss: 0.0615 | LR: 0.000176
Epoch 83/200 | Loss: 0.0562 | LR: 0.000175
Epoch 84/200 | Loss: 0.0511 | LR: 0.000173
Epoch 85/200 | Loss: 0.0469 | LR: 0.000171
Epoch 86/200 | Loss: 0.0432 | LR: 0.000169
Epoch 87/200 | Loss: 0.0403 | LR: 0.000167
Epoch 88/200 | Loss: 0.0366 | LR: 0.000165
Epoch 89/200 | Loss: 0.0341 | LR: 0.000163

Early stopping at epoch 90: both metrics declined for 3 consecutive evaluations.

Training finished at epoch 90.
Best Composite Accuracy: 0.1461 (epoch 60)
Best Symmetric Accuracy: 0.0344 (epoch 50)
Metrics saved to results/0_train_phase_diagram/L4_G0.3/metrics.json

Training completed successfully!
