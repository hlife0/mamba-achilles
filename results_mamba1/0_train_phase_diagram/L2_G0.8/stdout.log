Configuration saved to results/0_train_phase_diagram/L2_G0.8/config.json
Using device: cuda
Creating datasets...
Train dataset size: 300000
Eval dataset size: 1800
Creating model: MambaForComposite
Model parameters: 66,272

Starting training for 200 epochs...
Epoch 1/200 | Loss: 4.6170 | LR: 0.000010
Epoch 2/200 | Loss: 4.6149 | LR: 0.000034
Epoch 3/200 | Loss: 4.6105 | LR: 0.000058
Epoch 4/200 | Loss: 4.5981 | LR: 0.000082
Epoch 5/200 | Loss: 4.5582 | LR: 0.000106
Epoch 6/200 | Loss: 4.5109 | LR: 0.000130
Epoch 7/200 | Loss: 4.4127 | LR: 0.000154
Epoch 8/200 | Loss: 3.9189 | LR: 0.000178
Epoch 9/200 | Loss: 3.4363 | LR: 0.000202
Epoch 10/200 | Loss: 3.2404 | Comp Acc: 0.1206 (best: 0.1206@10) | Sym Acc: 0.0383 (best: 0.0383@10) | LR: 0.000226
Epoch 11/200 | Loss: 3.1358 | LR: 0.000250
Epoch 12/200 | Loss: 3.0527 | LR: 0.000250
Epoch 13/200 | Loss: 2.9826 | LR: 0.000250
Epoch 14/200 | Loss: 2.9249 | LR: 0.000250
Epoch 15/200 | Loss: 2.8605 | LR: 0.000250
Epoch 16/200 | Loss: 2.8084 | LR: 0.000250
Epoch 17/200 | Loss: 2.7632 | LR: 0.000249
Epoch 18/200 | Loss: 2.7125 | LR: 0.000249
Epoch 19/200 | Loss: 2.6607 | LR: 0.000249
Epoch 20/200 | Loss: 2.6184 | Comp Acc: 0.2400 (best: 0.2400@20) | Sym Acc: 0.0417 (best: 0.0417@20) | LR: 0.000249
Epoch 21/200 | Loss: 2.5823 | LR: 0.000248
Epoch 22/200 | Loss: 2.5336 | LR: 0.000248
Epoch 23/200 | Loss: 2.5022 | LR: 0.000248
Epoch 24/200 | Loss: 2.4795 | LR: 0.000247
Epoch 25/200 | Loss: 2.4552 | LR: 0.000247
Epoch 26/200 | Loss: 2.4162 | LR: 0.000246
Epoch 27/200 | Loss: 2.3825 | LR: 0.000246
Epoch 28/200 | Loss: 2.3509 | LR: 0.000245
Epoch 29/200 | Loss: 2.3227 | LR: 0.000245
Epoch 30/200 | Loss: 2.2848 | Comp Acc: 0.1961 (best: 0.2400@20) | Sym Acc: 0.0422 (best: 0.0422@30) | LR: 0.000244
Epoch 31/200 | Loss: 2.2598 | LR: 0.000243
Epoch 32/200 | Loss: 2.2231 | LR: 0.000243
Epoch 33/200 | Loss: 2.2037 | LR: 0.000242
Epoch 34/200 | Loss: 2.1630 | LR: 0.000241
Epoch 35/200 | Loss: 2.1412 | LR: 0.000241
Epoch 36/200 | Loss: 2.1240 | LR: 0.000240
Epoch 37/200 | Loss: 2.1064 | LR: 0.000239
Epoch 38/200 | Loss: 2.0881 | LR: 0.000238
Epoch 39/200 | Loss: 2.0694 | LR: 0.000237
Epoch 40/200 | Loss: 2.0480 | Comp Acc: 0.1883 (best: 0.2400@20) | Sym Acc: 0.0628 (best: 0.0628@40) | LR: 0.000236
Epoch 41/200 | Loss: 2.0215 | LR: 0.000236
Epoch 42/200 | Loss: 2.0009 | LR: 0.000235
Epoch 43/200 | Loss: 1.9797 | LR: 0.000234
Epoch 44/200 | Loss: 1.9541 | LR: 0.000233
Epoch 45/200 | Loss: 1.9176 | LR: 0.000232
Epoch 46/200 | Loss: 1.8799 | LR: 0.000230
Epoch 47/200 | Loss: 1.8584 | LR: 0.000229
Epoch 48/200 | Loss: 1.8383 | LR: 0.000228
Epoch 49/200 | Loss: 1.8087 | LR: 0.000227
Epoch 50/200 | Loss: 1.7746 | Comp Acc: 0.2022 (best: 0.2400@20) | Sym Acc: 0.0272 (best: 0.0628@40) | LR: 0.000226
Epoch 51/200 | Loss: 1.7458 | LR: 0.000225
Epoch 52/200 | Loss: 1.7088 | LR: 0.000223
Epoch 53/200 | Loss: 1.6426 | LR: 0.000222
Epoch 54/200 | Loss: 1.5971 | LR: 0.000221
Epoch 55/200 | Loss: 1.5679 | LR: 0.000220
Epoch 56/200 | Loss: 1.5408 | LR: 0.000218
Epoch 57/200 | Loss: 1.5113 | LR: 0.000217
Epoch 58/200 | Loss: 1.4880 | LR: 0.000216
Epoch 59/200 | Loss: 1.4373 | LR: 0.000214
Epoch 60/200 | Loss: 1.3972 | Comp Acc: 0.2578 (best: 0.2578@60) | Sym Acc: 0.0189 (best: 0.0628@40) | LR: 0.000213
Epoch 61/200 | Loss: 1.3657 | LR: 0.000211
Epoch 62/200 | Loss: 1.3205 | LR: 0.000210
Epoch 63/200 | Loss: 1.2877 | LR: 0.000208
Epoch 64/200 | Loss: 1.2559 | LR: 0.000207
Epoch 65/200 | Loss: 1.2283 | LR: 0.000205
Epoch 66/200 | Loss: 1.1919 | LR: 0.000204
Epoch 67/200 | Loss: 1.1319 | LR: 0.000202
Epoch 68/200 | Loss: 1.0893 | LR: 0.000201
Epoch 69/200 | Loss: 1.0608 | LR: 0.000199
Epoch 70/200 | Loss: 1.0345 | Comp Acc: 0.3950 (best: 0.3950@70) | Sym Acc: 0.0161 (best: 0.0628@40) | LR: 0.000197
Epoch 71/200 | Loss: 1.0077 | LR: 0.000196
Epoch 72/200 | Loss: 0.9816 | LR: 0.000194
Epoch 73/200 | Loss: 0.9535 | LR: 0.000192
Epoch 74/200 | Loss: 0.9117 | LR: 0.000191
Epoch 75/200 | Loss: 0.8823 | LR: 0.000189
Epoch 76/200 | Loss: 0.8427 | LR: 0.000187
Epoch 77/200 | Loss: 0.8028 | LR: 0.000185
Epoch 78/200 | Loss: 0.7797 | LR: 0.000184
Epoch 79/200 | Loss: 0.7605 | LR: 0.000182
Epoch 80/200 | Loss: 0.7255 | Comp Acc: 0.4617 (best: 0.4617@80) | Sym Acc: 0.0178 (best: 0.0628@40) | LR: 0.000180
Epoch 81/200 | Loss: 0.6910 | LR: 0.000178
Epoch 82/200 | Loss: 0.6556 | LR: 0.000176
Epoch 83/200 | Loss: 0.6202 | LR: 0.000175
Epoch 84/200 | Loss: 0.5959 | LR: 0.000173
Epoch 85/200 | Loss: 0.5760 | LR: 0.000171
Epoch 86/200 | Loss: 0.5402 | LR: 0.000169
Epoch 87/200 | Loss: 0.5042 | LR: 0.000167
Epoch 88/200 | Loss: 0.4723 | LR: 0.000165
Epoch 89/200 | Loss: 0.4595 | LR: 0.000163
Epoch 90/200 | Loss: 0.4312 | Comp Acc: 0.5839 (best: 0.5839@90) | Sym Acc: 0.0133 (best: 0.0628@40) | LR: 0.000161
Epoch 91/200 | Loss: 0.4095 | LR: 0.000159
Epoch 92/200 | Loss: 0.3778 | LR: 0.000158
Epoch 93/200 | Loss: 0.3637 | LR: 0.000156
Epoch 94/200 | Loss: 0.3487 | LR: 0.000154
Epoch 95/200 | Loss: 0.3379 | LR: 0.000152
Epoch 96/200 | Loss: 0.3275 | LR: 0.000150
Epoch 97/200 | Loss: 0.3173 | LR: 0.000148
Epoch 98/200 | Loss: 0.3068 | LR: 0.000146
Epoch 99/200 | Loss: 0.2978 | LR: 0.000144
Epoch 100/200 | Loss: 0.2834 | Comp Acc: 0.6317 (best: 0.6317@100) | Sym Acc: 0.0022 (best: 0.0628@40) | LR: 0.000142
Epoch 101/200 | Loss: 0.2714 | LR: 0.000140
Epoch 102/200 | Loss: 0.2651 | LR: 0.000138
Epoch 103/200 | Loss: 0.2509 | LR: 0.000136
Epoch 104/200 | Loss: 0.2380 | LR: 0.000134
Epoch 105/200 | Loss: 0.2299 | LR: 0.000132
Epoch 106/200 | Loss: 0.2229 | LR: 0.000130
Epoch 107/200 | Loss: 0.2142 | LR: 0.000128
Epoch 108/200 | Loss: 0.2054 | LR: 0.000126
Epoch 109/200 | Loss: 0.1981 | LR: 0.000124
Epoch 110/200 | Loss: 0.1908 | Comp Acc: 0.6628 (best: 0.6628@110) | Sym Acc: 0.0006 (best: 0.0628@40) | LR: 0.000122
Epoch 111/200 | Loss: 0.1827 | LR: 0.000120
Epoch 112/200 | Loss: 0.1779 | LR: 0.000118
Epoch 113/200 | Loss: 0.1742 | LR: 0.000116
Epoch 114/200 | Loss: 0.1663 | LR: 0.000114
Epoch 115/200 | Loss: 0.1634 | LR: 0.000112
Epoch 116/200 | Loss: 0.1562 | LR: 0.000110
Epoch 117/200 | Loss: 0.1514 | LR: 0.000108
Epoch 118/200 | Loss: 0.1459 | LR: 0.000106
Epoch 119/200 | Loss: 0.1431 | LR: 0.000104
Epoch 120/200 | Loss: 0.1388 | Comp Acc: 0.5983 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000102
Epoch 121/200 | Loss: 0.1357 | LR: 0.000101
Epoch 122/200 | Loss: 0.1318 | LR: 0.000099
Epoch 123/200 | Loss: 0.1286 | LR: 0.000097
Epoch 124/200 | Loss: 0.1263 | LR: 0.000095
Epoch 125/200 | Loss: 0.1237 | LR: 0.000093
Epoch 126/200 | Loss: 0.1205 | LR: 0.000091
Epoch 127/200 | Loss: 0.1176 | LR: 0.000089
Epoch 128/200 | Loss: 0.1146 | LR: 0.000087
Epoch 129/200 | Loss: 0.1124 | LR: 0.000085
Epoch 130/200 | Loss: 0.1103 | Comp Acc: 0.5317 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000084
Epoch 131/200 | Loss: 0.1085 | LR: 0.000082
Epoch 132/200 | Loss: 0.1069 | LR: 0.000080
Epoch 133/200 | Loss: 0.1048 | LR: 0.000078
Epoch 134/200 | Loss: 0.1034 | LR: 0.000076
Epoch 135/200 | Loss: 0.1013 | LR: 0.000075
Epoch 136/200 | Loss: 0.1000 | LR: 0.000073
Epoch 137/200 | Loss: 0.0983 | LR: 0.000071
Epoch 138/200 | Loss: 0.0966 | LR: 0.000069
Epoch 139/200 | Loss: 0.0950 | LR: 0.000068
Epoch 140/200 | Loss: 0.0943 | Comp Acc: 0.5039 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000066
Epoch 141/200 | Loss: 0.0924 | LR: 0.000064
Epoch 142/200 | Loss: 0.0913 | LR: 0.000063
Epoch 143/200 | Loss: 0.0900 | LR: 0.000061
Epoch 144/200 | Loss: 0.0892 | LR: 0.000059
Epoch 145/200 | Loss: 0.0877 | LR: 0.000058
Epoch 146/200 | Loss: 0.0865 | LR: 0.000056
Epoch 147/200 | Loss: 0.0856 | LR: 0.000055
Epoch 148/200 | Loss: 0.0847 | LR: 0.000053
Epoch 149/200 | Loss: 0.0833 | LR: 0.000052
Epoch 150/200 | Loss: 0.0827 | Comp Acc: 0.4750 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000050
Epoch 151/200 | Loss: 0.0815 | LR: 0.000049
Epoch 152/200 | Loss: 0.0807 | LR: 0.000047
Epoch 153/200 | Loss: 0.0797 | LR: 0.000046
Epoch 154/200 | Loss: 0.0788 | LR: 0.000044
Epoch 155/200 | Loss: 0.0783 | LR: 0.000043
Epoch 156/200 | Loss: 0.0776 | LR: 0.000042
Epoch 157/200 | Loss: 0.0768 | LR: 0.000040
Epoch 158/200 | Loss: 0.0759 | LR: 0.000039
Epoch 159/200 | Loss: 0.0752 | LR: 0.000038
Epoch 160/200 | Loss: 0.0745 | Comp Acc: 0.4561 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000037
Epoch 161/200 | Loss: 0.0742 | LR: 0.000035
Epoch 162/200 | Loss: 0.0733 | LR: 0.000034
Epoch 163/200 | Loss: 0.0729 | LR: 0.000033
Epoch 164/200 | Loss: 0.0722 | LR: 0.000032
Epoch 165/200 | Loss: 0.0716 | LR: 0.000031
Epoch 166/200 | Loss: 0.0711 | LR: 0.000030
Epoch 167/200 | Loss: 0.0708 | LR: 0.000028
Epoch 168/200 | Loss: 0.0702 | LR: 0.000027
Epoch 169/200 | Loss: 0.0696 | LR: 0.000026
Epoch 170/200 | Loss: 0.0693 | Comp Acc: 0.4489 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000025
Epoch 171/200 | Loss: 0.0688 | LR: 0.000024
Epoch 172/200 | Loss: 0.0684 | LR: 0.000024
Epoch 173/200 | Loss: 0.0680 | LR: 0.000023
Epoch 174/200 | Loss: 0.0676 | LR: 0.000022
Epoch 175/200 | Loss: 0.0672 | LR: 0.000021
Epoch 176/200 | Loss: 0.0669 | LR: 0.000020
Epoch 177/200 | Loss: 0.0665 | LR: 0.000019
Epoch 178/200 | Loss: 0.0662 | LR: 0.000019
Epoch 179/200 | Loss: 0.0659 | LR: 0.000018
Epoch 180/200 | Loss: 0.0656 | Comp Acc: 0.4378 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000017
Epoch 181/200 | Loss: 0.0652 | LR: 0.000017
Epoch 182/200 | Loss: 0.0649 | LR: 0.000016
Epoch 183/200 | Loss: 0.0646 | LR: 0.000015
Epoch 184/200 | Loss: 0.0644 | LR: 0.000015
Epoch 185/200 | Loss: 0.0642 | LR: 0.000014
Epoch 186/200 | Loss: 0.0640 | LR: 0.000014
Epoch 187/200 | Loss: 0.0638 | LR: 0.000013
Epoch 188/200 | Loss: 0.0635 | LR: 0.000013
Epoch 189/200 | Loss: 0.0632 | LR: 0.000012
Epoch 190/200 | Loss: 0.0631 | Comp Acc: 0.4300 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000012
Epoch 191/200 | Loss: 0.0629 | LR: 0.000012
Epoch 192/200 | Loss: 0.0627 | LR: 0.000011
Epoch 193/200 | Loss: 0.0624 | LR: 0.000011
Epoch 194/200 | Loss: 0.0624 | LR: 0.000011
Epoch 195/200 | Loss: 0.0622 | LR: 0.000011
Epoch 196/200 | Loss: 0.0621 | LR: 0.000010
Epoch 197/200 | Loss: 0.0618 | LR: 0.000010
Epoch 198/200 | Loss: 0.0616 | LR: 0.000010
Epoch 199/200 | Loss: 0.0615 | LR: 0.000010
Epoch 200/200 | Loss: 0.0614 | Comp Acc: 0.4306 (best: 0.6628@110) | Sym Acc: 0.0000 (best: 0.0628@40) | LR: 0.000010

Training finished at epoch 200.
Best Composite Accuracy: 0.6628 (epoch 110)
Best Symmetric Accuracy: 0.0628 (epoch 40)
Metrics saved to results/0_train_phase_diagram/L2_G0.8/metrics.json

Training completed successfully!
